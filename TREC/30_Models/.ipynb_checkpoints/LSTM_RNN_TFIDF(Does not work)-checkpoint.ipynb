{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xI1-62Pd-QJ1",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import metrics\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "import sklearn.model_selection as model_selection\n",
    "from keras.datasets import imdb\n",
    "from keras.preprocessing import sequence\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, SimpleRNN\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import shuffle\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "from keras.optimizers import SGD\n",
    "from numpy import newaxis\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from sklearn.metrics import classification_report\n",
    "import tensorflow as tf\n",
    "import io\n",
    "import re\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 139
    },
    "colab_type": "code",
    "id": "gaFUyTq2EOEk",
    "outputId": "16522609-47db-46f6-f7dc-fd88722b366c",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Vishaal\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Vishaal\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Vishaal\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Vishaal\\\\Documents\\\\GitHub\\\\TREC_Distributed_Machine_Learning\\\\TREC\\\\30_Models'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "os.chdir('../10_Data/30_Balanced Tweets (Crit = High = Medium = Low)/10_2018 Train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "    Loading Balanced earthquake and flood data from 2018 train. \n",
    "'''\n",
    "df_e1 = pd.read_csv('earthquake_TREC_2018_train_BALANCED.csv')\n",
    "df_f1 = pd.read_csv('flood_TREC_2018_train_BALANCED.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "os.chdir('../15_2018 Test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6NtIBkTiB3Y_",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "    Loading our test 2018 tweets from eathquakes and floods separately. These have a decent amount of critical tweets.\n",
    "    We did not include attacks as a considerable amount of work has been done on that before.\n",
    "'''\n",
    "df_e2 = pd.read_csv('earthquake_TREC_2018_test_BALANCED.csv')\n",
    "df_f2 = pd.read_csv('flood_TREC_2018_test_BALANCED.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "E3a2f-krBAw0",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "    Combining all earthquake tweets into one\n",
    "'''\n",
    "df_quake = pd.DataFrame()\n",
    "df_quake['Tweet'] = pd.concat([df_e1['Tweet'] , df_e2['Tweet']])\n",
    "df_quake['Priority'] = pd.concat([df_e1['Priority'] , df_e2['Priority']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    Combining all flood tweets into one\n",
    "'''\n",
    "df_flood = pd.DataFrame()\n",
    "df_flood['Tweet'] = pd.concat([df_f1['Tweet'] , df_f2['Tweet']])\n",
    "df_flood['Priority'] = pd.concat([df_f1['Priority'] , df_f2['Priority']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    Breaking up earthquake and flood tweets into low, med and high\n",
    "'''\n",
    "df_q_l = df_quake[(df_quake['Priority'] == 'Low') | (df_quake['Priority'] == 'Critical')]\n",
    "df_q_m = df_quake[(df_quake['Priority'] == 'Medium') | (df_quake['Priority'] == 'Critical')]\n",
    "df_q_h = df_quake[(df_quake['Priority'] == 'High') | (df_quake['Priority'] == 'Critical')]\n",
    "\n",
    "df_f_l = df_flood[(df_flood['Priority'] == 'Low') | (df_flood['Priority'] == 'Critical')]\n",
    "df_f_m = df_flood[(df_flood['Priority'] == 'Medium') | (df_flood['Priority'] == 'Critical')]\n",
    "df_f_h = df_flood[(df_flood['Priority'] == 'High') | (df_flood['Priority'] == 'Critical')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CxR68qNrCaBo",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Creating a categorical variable to keep label critical tweets as 1 and 0 otherwise\n",
    "'''\n",
    "def to_categorical(df_c):\n",
    "    t = []\n",
    "    for element in df_c['Priority']:\n",
    "        if element =='Critical':\n",
    "            t.append(1)\n",
    "        else:\n",
    "            t.append(0)\n",
    "    return t\n",
    "        \n",
    "t_q_l = to_categorical(df_q_l)\n",
    "t_q_m = to_categorical(df_q_m)\n",
    "t_q_h = to_categorical(df_q_h)\n",
    "t_f_l = to_categorical(df_f_l)\n",
    "t_f_m = to_categorical(df_f_m)\n",
    "t_f_h = to_categorical(df_f_h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    Shuffling dfs. CRITICAL TO MAKE IT LEARN...\n",
    "'''\n",
    "df_q_l, t_q_l = shuffle(df_q_l, t_q_l)\n",
    "df_q_m, t_q_m = shuffle(df_q_m, t_q_m)\n",
    "df_q_h, t_q_h = shuffle(df_q_h, t_q_h)\n",
    "\n",
    "df_f_l, t_f_l = shuffle(df_f_l, t_f_l)\n",
    "df_f_m, t_f_m = shuffle(df_f_m, t_f_m)\n",
    "df_f_h, t_f_h = shuffle(df_f_h, t_f_h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KF1ZxU1WCeRl",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "    Creating a function to input lemmatized text to possibly another function that outputs the tfidf in a csv format.\n",
    "    We could also simply use the output from this funtion in an tfidf format (no csv) and train a model.\n",
    "'''\n",
    "def preProcess(df):\n",
    "    df['Tweet'] = df['Tweet'].astype('str')\n",
    "    \n",
    "    df['Tweet'] = df['Tweet'].apply(lambda x: re.split('https?://\\S+', str(x))[0])\n",
    "    \n",
    "    token_array = []\n",
    "    for tweet in df['Tweet']:\n",
    "        token_tweet = word_tokenize(tweet)\n",
    "        token_array.append(token_tweet)\n",
    "        \n",
    "    stop_words=set(stopwords.words(\"english\"))\n",
    "    filtered_token_array=[]\n",
    "    for tweet in token_array:\n",
    "        filtered_tweet = []\n",
    "        for word in tweet:\n",
    "                if word not in stop_words:\n",
    "                    filtered_tweet.append(word)\n",
    "        filtered_token_array.append(filtered_tweet)\n",
    "        \n",
    "    lem = WordNetLemmatizer()\n",
    "    stem = PorterStemmer()\n",
    "\n",
    "    lemmatized_array=[]\n",
    "    for tweet in filtered_token_array:\n",
    "        lemmatized_tweet = []\n",
    "        for word in tweet:\n",
    "            lemmatized_tweet.append(lem.lemmatize(word,'v'))\n",
    "        lemmatized_array.append(lemmatized_tweet)\n",
    "    \n",
    "    lemmatized_array_join = []\n",
    "    for element in lemmatized_array:\n",
    "        lemmatized_array_join.append(' '.join(element))\n",
    "        \n",
    "    return (lemmatized_array_join)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FfuwkLE2l0Oz",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "    Plot no skill and ROC curve\n",
    "'''\n",
    "def plot_roc_curve(test_y, naive_probs, model_probs):\n",
    "\t# plot naive skill roc curve\n",
    "\tfpr, tpr, _ = roc_curve(test_y, naive_probs)\n",
    "\tplt.plot(fpr, tpr, linestyle='--', label='No Skill')\n",
    "\t# plot model roc curve\n",
    "\tfpr, tpr, _ = roc_curve(test_y, model_probs)\n",
    "\tplt.plot(fpr, tpr, marker='.', label='SVM SGD')\n",
    "\t# axis labels\n",
    "\tplt.xlabel('False Positive Rate')\n",
    "\tplt.ylabel('True Positive Rate')\n",
    "\t# show the legend\n",
    "\tplt.legend()\n",
    "\t# show the plot\n",
    "\tplt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "K_mM9-MWl4aM",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "    Plot no skill model and PR curve\n",
    "'''\n",
    "def plot_pr_curve(test_y, model_probs):\n",
    "\t# calculate the no skill line as the proportion of the positive class\n",
    "\tno_skill = len(test_y[test_y==1]) / len(test_y)\n",
    "\t# plot the no skill precision-recall curve\n",
    "\tplt.plot([0, 1], [no_skill, no_skill], linestyle='--', label='No Skill')\n",
    "\t# plot model precision-recall curve\n",
    "\tprecision, recall, _ = precision_recall_curve(test_y, model_probs)\n",
    "\tplt.plot(recall, precision, marker='.', label='SVM SGD')\n",
    "\t# axis labels\n",
    "\tplt.xlabel('Recall')\n",
    "\tplt.ylabel('Precision')\n",
    "\t# show the legend\n",
    "\tplt.legend()\n",
    "\t# show the plot\n",
    "\tplt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JWWgg2XHs20j",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def recall_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 228
    },
    "colab_type": "code",
    "id": "t_IZZlvJFvAw",
    "outputId": "752add9c-c8d2-463c-8eba-3fd1c8076656",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 35 samples, validate on 15 samples\n",
      "Epoch 1/50\n",
      "35/35 [==============================] - 2s 51ms/step - loss: 0.6946 - acc: 0.5429 - recall_2: 0.0000e+00 - precision_2: 0.0000e+00 - auc_2: 0.3816 - val_loss: 0.6959 - val_acc: 0.4000 - val_recall_2: 0.0000e+00 - val_precision_2: 0.0000e+00 - val_auc_2: 0.5556\n",
      "Epoch 2/50\n",
      "35/35 [==============================] - 1s 40ms/step - loss: 0.6952 - acc: 0.5429 - recall_2: 0.0000e+00 - precision_2: 0.0000e+00 - auc_2: 0.3043 - val_loss: 0.6968 - val_acc: 0.4000 - val_recall_2: 0.0000e+00 - val_precision_2: 0.0000e+00 - val_auc_2: 0.5556\n",
      "Epoch 3/50\n",
      "35/35 [==============================] - 1s 40ms/step - loss: 0.6930 - acc: 0.5429 - recall_2: 0.0000e+00 - precision_2: 0.0000e+00 - auc_2: 0.3487 - val_loss: 0.6967 - val_acc: 0.4000 - val_recall_2: 0.0000e+00 - val_precision_2: 0.0000e+00 - val_auc_2: 0.5556\n",
      "Epoch 4/50\n",
      "35/35 [==============================] - 1s 41ms/step - loss: 0.6938 - acc: 0.5429 - recall_2: 0.0000e+00 - precision_2: 0.0000e+00 - auc_2: 0.3240 - val_loss: 0.6980 - val_acc: 0.4000 - val_recall_2: 0.0000e+00 - val_precision_2: 0.0000e+00 - val_auc_2: 0.4722\n",
      "Epoch 5/50\n",
      "35/35 [==============================] - 1s 42ms/step - loss: 0.6921 - acc: 0.5429 - recall_2: 0.0000e+00 - precision_2: 0.0000e+00 - auc_2: 0.4079 - val_loss: 0.6982 - val_acc: 0.4000 - val_recall_2: 0.0000e+00 - val_precision_2: 0.0000e+00 - val_auc_2: 0.5926\n",
      "Epoch 6/50\n",
      "35/35 [==============================] - 1s 42ms/step - loss: 0.6914 - acc: 0.5429 - recall_2: 0.0000e+00 - precision_2: 0.0000e+00 - auc_2: 0.4030 - val_loss: 0.7013 - val_acc: 0.4000 - val_recall_2: 0.0000e+00 - val_precision_2: 0.0000e+00 - val_auc_2: 0.4722\n",
      "Epoch 7/50\n",
      "35/35 [==============================] - 2s 43ms/step - loss: 0.6921 - acc: 0.5429 - recall_2: 0.0000e+00 - precision_2: 0.0000e+00 - auc_2: 0.4326 - val_loss: 0.7019 - val_acc: 0.4000 - val_recall_2: 0.0000e+00 - val_precision_2: 0.0000e+00 - val_auc_2: 0.3889\n",
      "Epoch 8/50\n",
      "35/35 [==============================] - 2s 43ms/step - loss: 0.6905 - acc: 0.5429 - recall_2: 0.0000e+00 - precision_2: 0.0000e+00 - auc_2: 0.5099 - val_loss: 0.7045 - val_acc: 0.4000 - val_recall_2: 0.0000e+00 - val_precision_2: 0.0000e+00 - val_auc_2: 0.4630\n",
      "Epoch 9/50\n",
      "35/35 [==============================] - 2s 45ms/step - loss: 0.6915 - acc: 0.5429 - recall_2: 0.0000e+00 - precision_2: 0.0000e+00 - auc_2: 0.4457 - val_loss: 0.7042 - val_acc: 0.4000 - val_recall_2: 0.0000e+00 - val_precision_2: 0.0000e+00 - val_auc_2: 0.4630\n",
      "Epoch 10/50\n",
      "35/35 [==============================] - 2s 45ms/step - loss: 0.6900 - acc: 0.5429 - recall_2: 0.0000e+00 - precision_2: 0.0000e+00 - auc_2: 0.4194 - val_loss: 0.7047 - val_acc: 0.4000 - val_recall_2: 0.0000e+00 - val_precision_2: 0.0000e+00 - val_auc_2: 0.4444\n",
      "Epoch 11/50\n",
      "35/35 [==============================] - 2s 45ms/step - loss: 0.6908 - acc: 0.5429 - recall_2: 0.0000e+00 - precision_2: 0.0000e+00 - auc_2: 0.4934 - val_loss: 0.7063 - val_acc: 0.4000 - val_recall_2: 0.0000e+00 - val_precision_2: 0.0000e+00 - val_auc_2: 0.4630\n",
      "Epoch 12/50\n",
      "35/35 [==============================] - 2s 44ms/step - loss: 0.6904 - acc: 0.5429 - recall_2: 0.0000e+00 - precision_2: 0.0000e+00 - auc_2: 0.4770 - val_loss: 0.7071 - val_acc: 0.4000 - val_recall_2: 0.0000e+00 - val_precision_2: 0.0000e+00 - val_auc_2: 0.3889\n",
      "Epoch 13/50\n",
      "35/35 [==============================] - 2s 49ms/step - loss: 0.6916 - acc: 0.5429 - recall_2: 0.0000e+00 - precision_2: 0.0000e+00 - auc_2: 0.4375 - val_loss: 0.7060 - val_acc: 0.4000 - val_recall_2: 0.0000e+00 - val_precision_2: 0.0000e+00 - val_auc_2: 0.5185\n",
      "Epoch 14/50\n",
      "35/35 [==============================] - 2s 46ms/step - loss: 0.6866 - acc: 0.5429 - recall_2: 0.0000e+00 - precision_2: 0.0000e+00 - auc_2: 0.5132 - val_loss: 0.7262 - val_acc: 0.4000 - val_recall_2: 0.0000e+00 - val_precision_2: 0.0000e+00 - val_auc_2: 0.1759\n",
      "Epoch 15/50\n",
      "35/35 [==============================] - 1s 42ms/step - loss: 0.6912 - acc: 0.5143 - recall_2: 0.0000e+00 - precision_2: 0.0000e+00 - auc_2: 0.4885 - val_loss: 0.7164 - val_acc: 0.4000 - val_recall_2: 0.0000e+00 - val_precision_2: 0.0000e+00 - val_auc_2: 0.2315\n",
      "Epoch 16/50\n",
      "35/35 [==============================] - 2s 45ms/step - loss: 0.6895 - acc: 0.5429 - recall_2: 0.0000e+00 - precision_2: 0.0000e+00 - auc_2: 0.5263 - val_loss: 0.7152 - val_acc: 0.4000 - val_recall_2: 0.0000e+00 - val_precision_2: 0.0000e+00 - val_auc_2: 0.3148\n",
      "Epoch 17/50\n",
      "35/35 [==============================] - 2s 46ms/step - loss: 0.6833 - acc: 0.5714 - recall_2: 0.0625 - precision_2: 1.0000 - auc_2: 0.5559 - val_loss: 0.9998 - val_acc: 0.5333 - val_recall_2: 0.2222 - val_precision_2: 1.0000 - val_auc_2: 0.5741\n",
      "Epoch 18/50\n",
      "35/35 [==============================] - 2s 44ms/step - loss: 0.7810 - acc: 0.4571 - recall_2: 0.0625 - precision_2: 0.2000 - auc_2: 0.4062 - val_loss: 0.7038 - val_acc: 0.4000 - val_recall_2: 0.0000e+00 - val_precision_2: 0.0000e+00 - val_auc_2: 0.4815\n",
      "Epoch 19/50\n",
      "35/35 [==============================] - 2s 45ms/step - loss: 0.6894 - acc: 0.5143 - recall_2: 0.0000e+00 - precision_2: 0.0000e+00 - auc_2: 0.5477 - val_loss: 0.7040 - val_acc: 0.4000 - val_recall_2: 0.0000e+00 - val_precision_2: 0.0000e+00 - val_auc_2: 0.5556\n",
      "Epoch 20/50\n",
      "35/35 [==============================] - 2s 47ms/step - loss: 0.6879 - acc: 0.4857 - recall_2: 0.0000e+00 - precision_2: 0.0000e+00 - auc_2: 0.6184 - val_loss: 0.7056 - val_acc: 0.4000 - val_recall_2: 0.0000e+00 - val_precision_2: 0.0000e+00 - val_auc_2: 0.4444\n",
      "Epoch 21/50\n",
      "35/35 [==============================] - 2s 46ms/step - loss: 0.6848 - acc: 0.5143 - recall_2: 0.0000e+00 - precision_2: 0.0000e+00 - auc_2: 0.6234 - val_loss: 0.7058 - val_acc: 0.4000 - val_recall_2: 0.0000e+00 - val_precision_2: 0.0000e+00 - val_auc_2: 0.4444\n",
      "Epoch 22/50\n",
      "18/35 [==============>...............] - ETA: 0s - loss: 0.6938 - acc: 0.5000 - recall_2: 0.0000e+00 - precision_2: 0.0000e+00 - auc_2: 0.5247"
     ]
    }
   ],
   "source": [
    "'''\n",
    "    Getting a DTM of tf-idf features\n",
    "'''\n",
    "tf=TfidfVectorizer()\n",
    "lemmatized_array_join = preProcess(df_q_l)\n",
    "text_lc= tf.fit_transform(lemmatized_array_join)\n",
    "'''\n",
    "    Converting DTM to array. REQUIRED TO DIRECTLY TRAIN SVM\n",
    "'''\n",
    "text_lc= text_lc.toarray()\n",
    "\n",
    "'''\n",
    "  Keras expects a 3D input layer. So we will reshape our x and y s\n",
    "'''\n",
    "text_lc = text_lc[:,:,newaxis]\n",
    "t_lc = t_q_l\n",
    "\n",
    "'''\n",
    "    A simple RNN using embedding layer and a SimpleRNN layer. 32 is the number of dimensions we wish to \n",
    "    embed into. Like 8 in the previous example we did for word embeddings.\n",
    "'''\n",
    "model_lc = Sequential()\n",
    "model_lc.add(LSTM(units=100, input_shape = ( text_lc.shape[1], 1), dropout=0.2, return_sequences=False))\n",
    "model_lc.add(Dense(units=1, activation='sigmoid'))\n",
    "model_lc.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc', keras.metrics.Recall(), keras.metrics.Precision(), keras.metrics.AUC()])\n",
    "history_lc = model_lc.fit(text_lc, t_lc, epochs=50, batch_size=3, validation_split=0.3, shuffle = True )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(110, 820, 1)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_lc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['val_loss', 'val_recall_18', 'val_precision_15', 'loss', 'recall_18', 'precision_15'])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = history_lc.history\n",
    "result.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'val_recall_8'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-103-c24dac8bbd29>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'val_recall_8'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m: 'val_recall_8'"
     ]
    }
   ],
   "source": [
    "np.mean((result['val_recall_8']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "9Wj6tHG1kr1v",
    "outputId": "ce0e1ae8-dce7-4a63-a680-450d1259f991",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.69040567],\n",
       "       [0.69040567],\n",
       "       [0.69040567],\n",
       "       [0.690448  ],\n",
       "       [0.69040567],\n",
       "       [0.69040567],\n",
       "       [0.69040567],\n",
       "       [0.69040567],\n",
       "       [0.6904128 ],\n",
       "       [0.69040567],\n",
       "       [0.69040567],\n",
       "       [0.69040567],\n",
       "       [0.69040567],\n",
       "       [0.69040567],\n",
       "       [0.6904057 ],\n",
       "       [0.69048643],\n",
       "       [0.6904103 ],\n",
       "       [0.69440913],\n",
       "       [0.69040567],\n",
       "       [0.69040567],\n",
       "       [0.69040567],\n",
       "       [0.6904058 ],\n",
       "       [0.69040567],\n",
       "       [0.69040567],\n",
       "       [0.69040567],\n",
       "       [0.69040567],\n",
       "       [0.69040567],\n",
       "       [0.6904057 ],\n",
       "       [0.69040567],\n",
       "       [0.69040567],\n",
       "       [0.69040567],\n",
       "       [0.69053763],\n",
       "       [0.6962357 ],\n",
       "       [0.69040567],\n",
       "       [0.69040567],\n",
       "       [0.69040567],\n",
       "       [0.6905835 ],\n",
       "       [0.69040567],\n",
       "       [0.69040567],\n",
       "       [0.69040567],\n",
       "       [0.69041455],\n",
       "       [0.6904057 ],\n",
       "       [0.6909525 ],\n",
       "       [0.6910926 ],\n",
       "       [0.69040567],\n",
       "       [0.69040567],\n",
       "       [0.6904078 ],\n",
       "       [0.69040567],\n",
       "       [0.69040567],\n",
       "       [0.69040567],\n",
       "       [0.69040567],\n",
       "       [0.69042873],\n",
       "       [0.69040626],\n",
       "       [0.6904071 ],\n",
       "       [0.69040567],\n",
       "       [0.6904058 ]], dtype=float32)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_val = history_lc.validation_data\n",
    "y_pred = model_lc.predict(x_val[0])\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 299
    },
    "colab_type": "code",
    "id": "yrnHYHM1ZnXV",
    "outputId": "1ca4e1b8-32a5-428b-8c3a-8fe47d4d1aed"
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'acc'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-100-810e5b371983>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mPlotting\u001b[0m \u001b[0maccuracy\u001b[0m \u001b[0mVS\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mtraining\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mvalidations\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m '''\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0macc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhistory_lc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'acc'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mval_acc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhistory_lc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'val_acc'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhistory_lc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'loss'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'acc'"
     ]
    }
   ],
   "source": [
    "'''\n",
    "    Plotting accuracy VS epoch for training and validations\n",
    "'''\n",
    "acc = history_lc.history['acc']\n",
    "val_acc = history_lc.history['val_acc']\n",
    "loss = history_lc.history['loss']\n",
    "val_loss = history_lc.history['val_loss']\n",
    "epochs = range(1, len(acc) + 1)\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 299
    },
    "colab_type": "code",
    "id": "WCiZmozPZ6nf",
    "outputId": "d0b1a315-e0b2-4a45-cd54-0ce7a77bfe72"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1da74001e80>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "'''\n",
    "    Plotting loss VS epoch for training and validations\n",
    "'''\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 183
    },
    "colab_type": "code",
    "id": "B1CBJMFkjx-n",
    "outputId": "56ee467d-f21e-437e-8c34-dc0836077ef1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 328, 1)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_lc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 166
    },
    "colab_type": "code",
    "id": "l142dn_0jyna",
    "outputId": "70e564bd-17f1-420e-d207-7d5d094c2a91"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.29000655, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.2499344 , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.29000655, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.26656585, 0.        , 0.29000655, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.16628529,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.29000655, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.29000655,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.29000655, 0.        , 0.2499344 , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.23703406, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.21758196,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.29000655, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.29000655, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        ])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_lc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9oyAtdThkCgJ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "cQC6vIT7n7sq",
    "outputId": "d1e01f84-933d-4847-e498-45271df1cfa6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15865,)"
      ]
     },
     "execution_count": 39,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "u6j1daCdn_4Z"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        ...,\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.27651335],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        ...,\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        ...,\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        ...,\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        ...,\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        ...,\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ]]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_lc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "TREC_RNN.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
