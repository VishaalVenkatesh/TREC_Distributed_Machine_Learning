{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "wAGh7tgOpDj7",
    "outputId": "274b0f6d-655d-44b2-9997-2f653829c26e",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import metrics\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "import sklearn.model_selection as model_selection\n",
    "from keras.datasets import imdb\n",
    "from keras.preprocessing import sequence\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, SimpleRNN\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import shuffle\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "from keras.optimizers import SGD, RMSprop\n",
    "from numpy import newaxis\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from sklearn.metrics import classification_report\n",
    "import tensorflow as tf\n",
    "import io\n",
    "from tensorflow.keras import layers\n",
    "from keras.layers import GlobalAveragePooling1D, Conv1D, Conv2D\n",
    "import re\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hWDPPiyfA_hx",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "from numpy import array\n",
    "from keras.preprocessing.text import one_hot\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 139
    },
    "colab_type": "code",
    "id": "0gitmNze_ojF",
    "outputId": "4cfefae2-03ba-4d67-cc78-eb9a69bc1e06",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Vishaal\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Vishaal\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Vishaal\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "import os\n",
    "import pandas as pd\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "os.chdir('../10_Data/30_Balanced Tweets (Crit = High = Medium = Low)/10_2018 Train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Vishaal\\\\Documents\\\\GitHub\\\\TREC_Distributed_Machine_Learning\\\\TREC\\\\10_Data\\\\30_Balanced Tweets (Crit = High = Medium = Low)\\\\10_2018 Train'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    Loading Balanced earthquake and flood data from 2018 train. \n",
    "'''\n",
    "df_e1 = pd.read_csv('earthquake_TREC_2018_train_BALANCED.csv')\n",
    "df_f1 = pd.read_csv('flood_TREC_2018_train_BALANCED.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('../15_2018 Test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    Loading our test 2018 tweets from eathquakes and floods separately. These have a decent amount of critical tweets.\n",
    "    We did not include attacks as a considerable amount of work has been done on that before.\n",
    "'''\n",
    "df_e2 = pd.read_csv('earthquake_TREC_2018_test_BALANCED.csv')\n",
    "df_f2 = pd.read_csv('flood_TREC_2018_test_BALANCED.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    Combining all earthquake tweets into one\n",
    "'''\n",
    "df_quake = pd.DataFrame()\n",
    "df_quake['Tweet'] = pd.concat([df_e1['Tweet'] , df_e2['Tweet']])\n",
    "df_quake['Priority'] = pd.concat([df_e1['Priority'] , df_e2['Priority']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    Combining all flood tweets into one\n",
    "'''\n",
    "df_flood = pd.DataFrame()\n",
    "df_flood['Tweet'] = pd.concat([df_f1['Tweet'] , df_f2['Tweet']])\n",
    "df_flood['Priority'] = pd.concat([df_f1['Priority'] , df_f2['Priority']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    Breaking up earthquake and flood tweets into low, med and high\n",
    "'''\n",
    "df_q_l = df_quake[(df_quake['Priority'] == 'Low') | (df_quake['Priority'] == 'Critical')]\n",
    "df_q_m = df_quake[(df_quake['Priority'] == 'Medium') | (df_quake['Priority'] == 'Critical')]\n",
    "df_q_h = df_quake[(df_quake['Priority'] == 'High') | (df_quake['Priority'] == 'Critical')]\n",
    "\n",
    "df_f_l = df_flood[(df_flood['Priority'] == 'Low') | (df_flood['Priority'] == 'Critical')]\n",
    "df_f_m = df_flood[(df_flood['Priority'] == 'Medium') | (df_flood['Priority'] == 'Critical')]\n",
    "df_f_h = df_flood[(df_flood['Priority'] == 'High') | (df_flood['Priority'] == 'Critical')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rh3quY1lAbOv",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Creating a categorical variable to keep label critical tweets as 1 and 0 otherwise\n",
    "'''\n",
    "def to_categorical(df_c):\n",
    "    t = []\n",
    "    for element in df_c['Priority']:\n",
    "        if element =='Critical':\n",
    "            t.append(1)\n",
    "        else:\n",
    "            t.append(0)\n",
    "    return t\n",
    "        \n",
    "t_q_l = to_categorical(df_q_l)\n",
    "t_q_m = to_categorical(df_q_m)\n",
    "t_q_h = to_categorical(df_q_h)\n",
    "t_f_l = to_categorical(df_f_l)\n",
    "t_f_m = to_categorical(df_f_m)\n",
    "t_f_h = to_categorical(df_f_h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    Shuffling dfs. CRITICAL TO MAKE IT LEARN...\n",
    "'''\n",
    "df_q_l, t_q_l = shuffle(df_q_l, t_q_l)\n",
    "df_q_m, t_q_m = shuffle(df_q_m, t_q_m)\n",
    "df_q_h, t_q_h = shuffle(df_q_h, t_q_h)\n",
    "\n",
    "df_f_l, t_f_l = shuffle(df_f_l, t_f_l)\n",
    "df_f_m, t_f_m = shuffle(df_f_m, t_f_m)\n",
    "df_f_h, t_f_h = shuffle(df_f_h, t_f_h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "Qz01zcMJA45Z",
    "outputId": "354c5334-502a-4be0-f773-1fcdbaa51cc2",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "    Creating a function to input lemmatized text to possibly another function that outputs the tfidf in a csv format.\n",
    "    We could also simply use the output from this funtion in an tfidf format (no csv) and train a model.\n",
    "'''\n",
    "def preProcess(df):\n",
    "    df['Tweet'] = df['Tweet'].astype('str')\n",
    "    \n",
    "    df['Tweet'] = df['Tweet'].apply(lambda x: re.split('https?://\\S+', str(x))[0])\n",
    "    \n",
    "    token_array = []\n",
    "    for tweet in df['Tweet']:\n",
    "        token_tweet = word_tokenize(tweet)\n",
    "        token_array.append(token_tweet)\n",
    "        \n",
    "    stop_words=set(stopwords.words(\"english\"))\n",
    "    filtered_token_array=[]\n",
    "    for tweet in token_array:\n",
    "        filtered_tweet = []\n",
    "        for word in tweet:\n",
    "                if word not in stop_words:\n",
    "                    filtered_tweet.append(word)\n",
    "        filtered_token_array.append(filtered_tweet)\n",
    "        \n",
    "    lem = WordNetLemmatizer()\n",
    "    stem = PorterStemmer()\n",
    "\n",
    "    lemmatized_array=[]\n",
    "    for tweet in filtered_token_array:\n",
    "        lemmatized_tweet = []\n",
    "        for word in tweet:\n",
    "            lemmatized_tweet.append(lem.lemmatize(word,'v'))\n",
    "        lemmatized_array.append(lemmatized_tweet)\n",
    "    \n",
    "    lemmatized_array_join = []\n",
    "    for element in lemmatized_array:\n",
    "        lemmatized_array_join.append(' '.join(element))\n",
    "        \n",
    "    return (lemmatized_array_join)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iQn3lpACA6dG",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Vishaal\\Anaconda3_Mod\\lib\\site-packages\\ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "C:\\Users\\Vishaal\\Anaconda3_Mod\\lib\\site-packages\\ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "  We tokenize the lemmatized tweets to then do word embeddings\n",
    "'''\n",
    "l = preProcess(df_q_l)\n",
    "\n",
    "all_words = []\n",
    "\n",
    "for tweet in l:\n",
    "    tokenize_word = word_tokenize(tweet)\n",
    "    for word in tokenize_word:\n",
    "        all_words.append(word)\n",
    "'''\n",
    "    Getting the unique words out\n",
    "'''\n",
    "unique_words = set(all_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "    Getting embedded sentences\n",
    "'''\n",
    "vocab_length = len(unique_words)\n",
    "\n",
    "embedded_sentences = [one_hot(tweet, vocab_length) for tweet in l]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "    Making the size of all embeddings equal to the longest one\n",
    "'''\n",
    "word_count = lambda sentence: len(word_tokenize(sentence))\n",
    "longest_sentence = max(l, key=word_count)\n",
    "length_long_sentence = len(word_tokenize(longest_sentence))\n",
    "padded_sentences = pad_sequences(embedded_sentences, length_long_sentence, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 34)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_sentences.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "387"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "length_long_sentence "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Vishaal\\Anaconda3_Mod\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 35 samples, validate on 15 samples\n",
      "Epoch 1/100\n",
      "35/35 [==============================] - 6s 176ms/step - loss: 0.6933 - acc: 0.5143 - precision_33: 0.2500 - recall_33: 0.0667 - auc_33: 0.4083 - val_loss: 0.6936 - val_acc: 0.3333 - val_precision_33: 0.0000e+00 - val_recall_33: 0.0000e+00 - val_auc_33: 0.7000\n",
      "Epoch 2/100\n",
      "35/35 [==============================] - 2s 49ms/step - loss: 0.6921 - acc: 0.5714 - precision_33: 0.0000e+00 - recall_33: 0.0000e+00 - auc_33: 0.4700 - val_loss: 0.6953 - val_acc: 0.3333 - val_precision_33: 0.0000e+00 - val_recall_33: 0.0000e+00 - val_auc_33: 0.8400\n",
      "Epoch 3/100\n",
      "35/35 [==============================] - 2s 49ms/step - loss: 0.6893 - acc: 0.5714 - precision_33: 0.0000e+00 - recall_33: 0.0000e+00 - auc_33: 0.6867 - val_loss: 0.6968 - val_acc: 0.3333 - val_precision_33: 0.0000e+00 - val_recall_33: 0.0000e+00 - val_auc_33: 0.7000\n",
      "Epoch 4/100\n",
      "35/35 [==============================] - 2s 49ms/step - loss: 0.6864 - acc: 0.5714 - precision_33: 0.0000e+00 - recall_33: 0.0000e+00 - auc_33: 0.7800 - val_loss: 0.6990 - val_acc: 0.3333 - val_precision_33: 0.0000e+00 - val_recall_33: 0.0000e+00 - val_auc_33: 0.7000\n",
      "Epoch 5/100\n",
      "35/35 [==============================] - 2s 52ms/step - loss: 0.6831 - acc: 0.5714 - precision_33: 0.0000e+00 - recall_33: 0.0000e+00 - auc_33: 0.7800 - val_loss: 0.7010 - val_acc: 0.3333 - val_precision_33: 0.0000e+00 - val_recall_33: 0.0000e+00 - val_auc_33: 0.6800\n",
      "Epoch 6/100\n",
      "35/35 [==============================] - 2s 62ms/step - loss: 0.6790 - acc: 0.5714 - precision_33: 0.0000e+00 - recall_33: 0.0000e+00 - auc_33: 0.8067 - val_loss: 0.7045 - val_acc: 0.3333 - val_precision_33: 0.0000e+00 - val_recall_33: 0.0000e+00 - val_auc_33: 0.7100\n",
      "Epoch 7/100\n",
      "35/35 [==============================] - 2s 62ms/step - loss: 0.6736 - acc: 0.5714 - precision_33: 0.0000e+00 - recall_33: 0.0000e+00 - auc_33: 0.7883 - val_loss: 0.7085 - val_acc: 0.3333 - val_precision_33: 0.0000e+00 - val_recall_33: 0.0000e+00 - val_auc_33: 0.7200\n",
      "Epoch 8/100\n",
      "35/35 [==============================] - 2s 63ms/step - loss: 0.6664 - acc: 0.5714 - precision_33: 0.0000e+00 - recall_33: 0.0000e+00 - auc_33: 0.8383 - val_loss: 0.7152 - val_acc: 0.3333 - val_precision_33: 0.0000e+00 - val_recall_33: 0.0000e+00 - val_auc_33: 0.7100\n",
      "Epoch 9/100\n",
      "35/35 [==============================] - 2s 67ms/step - loss: 0.6591 - acc: 0.5714 - precision_33: 0.0000e+00 - recall_33: 0.0000e+00 - auc_33: 0.8200 - val_loss: 0.7201 - val_acc: 0.3333 - val_precision_33: 0.0000e+00 - val_recall_33: 0.0000e+00 - val_auc_33: 0.7200\n",
      "Epoch 10/100\n",
      "35/35 [==============================] - 2s 60ms/step - loss: 0.6521 - acc: 0.6000 - precision_33: 1.0000 - recall_33: 0.0667 - auc_33: 0.8317 - val_loss: 0.7251 - val_acc: 0.3333 - val_precision_33: 0.0000e+00 - val_recall_33: 0.0000e+00 - val_auc_33: 0.7100\n",
      "Epoch 11/100\n",
      "35/35 [==============================] - 2s 53ms/step - loss: 0.6418 - acc: 0.6286 - precision_33: 1.0000 - recall_33: 0.1333 - auc_33: 0.8700 - val_loss: 0.7345 - val_acc: 0.3333 - val_precision_33: 0.0000e+00 - val_recall_33: 0.0000e+00 - val_auc_33: 0.7200\n",
      "Epoch 12/100\n",
      "35/35 [==============================] - 2s 54ms/step - loss: 0.6323 - acc: 0.6571 - precision_33: 1.0000 - recall_33: 0.2000 - auc_33: 0.8617 - val_loss: 0.7381 - val_acc: 0.4667 - val_precision_33: 1.0000 - val_recall_33: 0.2000 - val_auc_33: 0.7200\n",
      "Epoch 13/100\n",
      "35/35 [==============================] - 2s 49ms/step - loss: 0.6244 - acc: 0.6571 - precision_33: 1.0000 - recall_33: 0.2000 - auc_33: 0.8650 - val_loss: 0.7448 - val_acc: 0.4667 - val_precision_33: 1.0000 - val_recall_33: 0.2000 - val_auc_33: 0.7000\n",
      "Epoch 14/100\n",
      "35/35 [==============================] - 2s 55ms/step - loss: 0.6150 - acc: 0.6571 - precision_33: 1.0000 - recall_33: 0.2000 - auc_33: 0.8867 - val_loss: 0.7519 - val_acc: 0.4667 - val_precision_33: 1.0000 - val_recall_33: 0.2000 - val_auc_33: 0.7000\n",
      "Epoch 15/100\n",
      "35/35 [==============================] - 2s 53ms/step - loss: 0.6014 - acc: 0.7143 - precision_33: 1.0000 - recall_33: 0.3333 - auc_33: 0.8983 - val_loss: 0.7542 - val_acc: 0.4667 - val_precision_33: 1.0000 - val_recall_33: 0.2000 - val_auc_33: 0.7000\n",
      "Epoch 16/100\n",
      "35/35 [==============================] - 2s 54ms/step - loss: 0.5920 - acc: 0.7714 - precision_33: 1.0000 - recall_33: 0.4667 - auc_33: 0.9150 - val_loss: 0.7642 - val_acc: 0.4667 - val_precision_33: 1.0000 - val_recall_33: 0.2000 - val_auc_33: 0.6900\n",
      "Epoch 17/100\n",
      "35/35 [==============================] - 2s 53ms/step - loss: 0.5767 - acc: 0.7714 - precision_33: 1.0000 - recall_33: 0.4667 - auc_33: 0.9383 - val_loss: 0.7735 - val_acc: 0.4667 - val_precision_33: 1.0000 - val_recall_33: 0.2000 - val_auc_33: 0.7000\n",
      "Epoch 18/100\n",
      "35/35 [==============================] - 2s 51ms/step - loss: 0.5611 - acc: 0.8286 - precision_33: 1.0000 - recall_33: 0.6000 - auc_33: 0.9400 - val_loss: 0.7818 - val_acc: 0.4667 - val_precision_33: 1.0000 - val_recall_33: 0.2000 - val_auc_33: 0.6900\n",
      "Epoch 19/100\n",
      "35/35 [==============================] - 2s 59ms/step - loss: 0.5468 - acc: 0.8286 - precision_33: 1.0000 - recall_33: 0.6000 - auc_33: 0.9617 - val_loss: 0.7951 - val_acc: 0.4667 - val_precision_33: 1.0000 - val_recall_33: 0.2000 - val_auc_33: 0.6900\n",
      "Epoch 20/100\n",
      "35/35 [==============================] - 2s 62ms/step - loss: 0.5370 - acc: 0.8571 - precision_33: 1.0000 - recall_33: 0.6667 - auc_33: 0.9667 - val_loss: 0.8011 - val_acc: 0.4667 - val_precision_33: 1.0000 - val_recall_33: 0.2000 - val_auc_33: 0.6900\n",
      "Epoch 21/100\n",
      "35/35 [==============================] - 2s 48ms/step - loss: 0.5217 - acc: 0.8571 - precision_33: 1.0000 - recall_33: 0.6667 - auc_33: 0.9683 - val_loss: 0.8109 - val_acc: 0.4667 - val_precision_33: 1.0000 - val_recall_33: 0.2000 - val_auc_33: 0.6900\n",
      "Epoch 22/100\n",
      "35/35 [==============================] - 2s 49ms/step - loss: 0.5016 - acc: 0.8571 - precision_33: 1.0000 - recall_33: 0.6667 - auc_33: 0.9817 - val_loss: 0.8175 - val_acc: 0.4000 - val_precision_33: 0.6667 - val_recall_33: 0.2000 - val_auc_33: 0.6800\n",
      "Epoch 23/100\n",
      "35/35 [==============================] - 2s 51ms/step - loss: 0.4814 - acc: 0.8857 - precision_33: 0.9231 - recall_33: 0.8000 - auc_33: 0.9750 - val_loss: 0.8224 - val_acc: 0.4000 - val_precision_33: 0.6667 - val_recall_33: 0.2000 - val_auc_33: 0.6800\n",
      "Epoch 24/100\n",
      "35/35 [==============================] - 2s 49ms/step - loss: 0.4507 - acc: 0.9143 - precision_33: 1.0000 - recall_33: 0.8000 - auc_33: 0.9967 - val_loss: 0.8242 - val_acc: 0.4000 - val_precision_33: 0.6667 - val_recall_33: 0.2000 - val_auc_33: 0.6800\n",
      "Epoch 25/100\n",
      "35/35 [==============================] - 2s 52ms/step - loss: 0.4399 - acc: 0.9143 - precision_33: 0.9286 - recall_33: 0.8667 - auc_33: 0.9833 - val_loss: 0.8397 - val_acc: 0.4000 - val_precision_33: 0.6667 - val_recall_33: 0.2000 - val_auc_33: 0.6800\n",
      "Epoch 26/100\n",
      "35/35 [==============================] - 2s 51ms/step - loss: 0.4202 - acc: 0.8857 - precision_33: 0.9231 - recall_33: 0.8000 - auc_33: 0.9867 - val_loss: 0.8264 - val_acc: 0.4000 - val_precision_33: 0.6000 - val_recall_33: 0.3000 - val_auc_33: 0.6800\n",
      "Epoch 27/100\n",
      "35/35 [==============================] - 2s 49ms/step - loss: 0.3999 - acc: 0.9429 - precision_33: 0.9333 - recall_33: 0.9333 - auc_33: 0.9933 - val_loss: 0.8370 - val_acc: 0.4000 - val_precision_33: 0.6000 - val_recall_33: 0.3000 - val_auc_33: 0.6900\n",
      "Epoch 28/100\n",
      "35/35 [==============================] - 2s 50ms/step - loss: 0.3823 - acc: 0.9429 - precision_33: 0.9333 - recall_33: 0.9333 - auc_33: 0.9967 - val_loss: 0.8581 - val_acc: 0.4000 - val_precision_33: 0.6000 - val_recall_33: 0.3000 - val_auc_33: 0.6800\n",
      "Epoch 29/100\n",
      "35/35 [==============================] - 2s 48ms/step - loss: 0.3550 - acc: 0.9714 - precision_33: 1.0000 - recall_33: 0.9333 - auc_33: 0.9983 - val_loss: 0.8776 - val_acc: 0.4000 - val_precision_33: 0.6000 - val_recall_33: 0.3000 - val_auc_33: 0.7000\n",
      "Epoch 30/100\n",
      "35/35 [==============================] - 2s 49ms/step - loss: 0.3557 - acc: 0.9429 - precision_33: 0.9333 - recall_33: 0.9333 - auc_33: 0.9967 - val_loss: 0.8849 - val_acc: 0.4000 - val_precision_33: 0.6000 - val_recall_33: 0.3000 - val_auc_33: 0.6900\n",
      "Epoch 31/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - 2s 57ms/step - loss: 0.3307 - acc: 0.9714 - precision_33: 1.0000 - recall_33: 0.9333 - auc_33: 0.9967 - val_loss: 0.8947 - val_acc: 0.4000 - val_precision_33: 0.6000 - val_recall_33: 0.3000 - val_auc_33: 0.7000\n",
      "Epoch 32/100\n",
      "35/35 [==============================] - 2s 52ms/step - loss: 0.3047 - acc: 1.0000 - precision_33: 1.0000 - recall_33: 1.0000 - auc_33: 1.0000 - val_loss: 0.9109 - val_acc: 0.4667 - val_precision_33: 0.7500 - val_recall_33: 0.3000 - val_auc_33: 0.7000\n",
      "Epoch 33/100\n",
      "35/35 [==============================] - 2s 52ms/step - loss: 0.3005 - acc: 0.9714 - precision_33: 1.0000 - recall_33: 0.9333 - auc_33: 1.0000 - val_loss: 0.9095 - val_acc: 0.4667 - val_precision_33: 0.6667 - val_recall_33: 0.4000 - val_auc_33: 0.7200\n",
      "Epoch 34/100\n",
      "35/35 [==============================] - 2s 49ms/step - loss: 0.2770 - acc: 1.0000 - precision_33: 1.0000 - recall_33: 1.0000 - auc_33: 1.0000 - val_loss: 0.9171 - val_acc: 0.4667 - val_precision_33: 0.6667 - val_recall_33: 0.4000 - val_auc_33: 0.7400\n",
      "Epoch 35/100\n",
      "35/35 [==============================] - 2s 65ms/step - loss: 0.2616 - acc: 1.0000 - precision_33: 1.0000 - recall_33: 1.0000 - auc_33: 1.0000 - val_loss: 0.9313 - val_acc: 0.4667 - val_precision_33: 0.6667 - val_recall_33: 0.4000 - val_auc_33: 0.7400\n",
      "Epoch 36/100\n",
      "35/35 [==============================] - 2s 59ms/step - loss: 0.2487 - acc: 1.0000 - precision_33: 1.0000 - recall_33: 1.0000 - auc_33: 1.0000 - val_loss: 0.9396 - val_acc: 0.5333 - val_precision_33: 0.8000 - val_recall_33: 0.4000 - val_auc_33: 0.7300\n",
      "Epoch 37/100\n",
      "35/35 [==============================] - 2s 65ms/step - loss: 0.2381 - acc: 1.0000 - precision_33: 1.0000 - recall_33: 1.0000 - auc_33: 1.0000 - val_loss: 0.9502 - val_acc: 0.5333 - val_precision_33: 0.8000 - val_recall_33: 0.4000 - val_auc_33: 0.7100\n",
      "Epoch 38/100\n",
      "35/35 [==============================] - 2s 47ms/step - loss: 0.2258 - acc: 1.0000 - precision_33: 1.0000 - recall_33: 1.0000 - auc_33: 1.0000 - val_loss: 0.9586 - val_acc: 0.5333 - val_precision_33: 0.8000 - val_recall_33: 0.4000 - val_auc_33: 0.7100\n",
      "Epoch 39/100\n",
      "35/35 [==============================] - 2s 46ms/step - loss: 0.2148 - acc: 1.0000 - precision_33: 1.0000 - recall_33: 1.0000 - auc_33: 1.0000 - val_loss: 0.9705 - val_acc: 0.5333 - val_precision_33: 0.8000 - val_recall_33: 0.4000 - val_auc_33: 0.7000\n",
      "Epoch 40/100\n",
      "35/35 [==============================] - 2s 52ms/step - loss: 0.2038 - acc: 1.0000 - precision_33: 1.0000 - recall_33: 1.0000 - auc_33: 1.0000 - val_loss: 1.0100 - val_acc: 0.4667 - val_precision_33: 0.6667 - val_recall_33: 0.4000 - val_auc_33: 0.6800\n",
      "Epoch 41/100\n",
      "35/35 [==============================] - 2s 59ms/step - loss: 0.2011 - acc: 1.0000 - precision_33: 1.0000 - recall_33: 1.0000 - auc_33: 1.0000 - val_loss: 0.9549 - val_acc: 0.5333 - val_precision_33: 1.0000 - val_recall_33: 0.3000 - val_auc_33: 0.7200\n",
      "Epoch 42/100\n",
      "35/35 [==============================] - 2s 49ms/step - loss: 0.1875 - acc: 1.0000 - precision_33: 1.0000 - recall_33: 1.0000 - auc_33: 1.0000 - val_loss: 0.9653 - val_acc: 0.5333 - val_precision_33: 1.0000 - val_recall_33: 0.3000 - val_auc_33: 0.7200\n",
      "Epoch 43/100\n",
      "35/35 [==============================] - 2s 46ms/step - loss: 0.1789 - acc: 1.0000 - precision_33: 1.0000 - recall_33: 1.0000 - auc_33: 1.0000 - val_loss: 0.9732 - val_acc: 0.5333 - val_precision_33: 1.0000 - val_recall_33: 0.3000 - val_auc_33: 0.7200\n",
      "Epoch 44/100\n",
      "35/35 [==============================] - 2s 49ms/step - loss: 0.1710 - acc: 1.0000 - precision_33: 1.0000 - recall_33: 1.0000 - auc_33: 1.0000 - val_loss: 0.9842 - val_acc: 0.5333 - val_precision_33: 1.0000 - val_recall_33: 0.3000 - val_auc_33: 0.7700\n",
      "Epoch 45/100\n",
      "35/35 [==============================] - 2s 56ms/step - loss: 0.1647 - acc: 1.0000 - precision_33: 1.0000 - recall_33: 1.0000 - auc_33: 1.0000 - val_loss: 0.9895 - val_acc: 0.5333 - val_precision_33: 1.0000 - val_recall_33: 0.3000 - val_auc_33: 0.7300\n",
      "Epoch 46/100\n",
      "35/35 [==============================] - 3s 73ms/step - loss: 0.1564 - acc: 1.0000 - precision_33: 1.0000 - recall_33: 1.0000 - auc_33: 1.0000 - val_loss: 0.9947 - val_acc: 0.5333 - val_precision_33: 1.0000 - val_recall_33: 0.3000 - val_auc_33: 0.7800\n",
      "Epoch 47/100\n",
      "35/35 [==============================] - 2s 71ms/step - loss: 0.1485 - acc: 1.0000 - precision_33: 1.0000 - recall_33: 1.0000 - auc_33: 1.0000 - val_loss: 1.0055 - val_acc: 0.5333 - val_precision_33: 1.0000 - val_recall_33: 0.3000 - val_auc_33: 0.7800\n",
      "Epoch 48/100\n",
      "35/35 [==============================] - 2s 69ms/step - loss: 0.1415 - acc: 1.0000 - precision_33: 1.0000 - recall_33: 1.0000 - auc_33: 1.0000 - val_loss: 1.0094 - val_acc: 0.5333 - val_precision_33: 1.0000 - val_recall_33: 0.3000 - val_auc_33: 0.7600\n",
      "Epoch 49/100\n",
      "35/35 [==============================] - 2s 67ms/step - loss: 0.1340 - acc: 1.0000 - precision_33: 1.0000 - recall_33: 1.0000 - auc_33: 1.0000 - val_loss: 1.0279 - val_acc: 0.5333 - val_precision_33: 1.0000 - val_recall_33: 0.3000 - val_auc_33: 0.7600\n",
      "Epoch 50/100\n",
      "35/35 [==============================] - 2s 71ms/step - loss: 0.1262 - acc: 1.0000 - precision_33: 1.0000 - recall_33: 1.0000 - auc_33: 1.0000 - val_loss: 1.0480 - val_acc: 0.5333 - val_precision_33: 1.0000 - val_recall_33: 0.3000 - val_auc_33: 0.7400\n",
      "Epoch 51/100\n",
      "35/35 [==============================] - 3s 74ms/step - loss: 0.1194 - acc: 1.0000 - precision_33: 1.0000 - recall_33: 1.0000 - auc_33: 1.0000 - val_loss: 1.0510 - val_acc: 0.5333 - val_precision_33: 1.0000 - val_recall_33: 0.3000 - val_auc_33: 0.7600\n",
      "Epoch 52/100\n",
      "35/35 [==============================] - 2s 67ms/step - loss: 0.1132 - acc: 1.0000 - precision_33: 1.0000 - recall_33: 1.0000 - auc_33: 1.0000 - val_loss: 1.1071 - val_acc: 0.6000 - val_precision_33: 1.0000 - val_recall_33: 0.4000 - val_auc_33: 0.7200\n",
      "Epoch 53/100\n",
      "35/35 [==============================] - 3s 74ms/step - loss: 0.1074 - acc: 1.0000 - precision_33: 1.0000 - recall_33: 1.0000 - auc_33: 1.0000 - val_loss: 1.1045 - val_acc: 0.6000 - val_precision_33: 1.0000 - val_recall_33: 0.4000 - val_auc_33: 0.6800\n",
      "Epoch 54/100\n",
      "35/35 [==============================] - 2s 56ms/step - loss: 0.1012 - acc: 1.0000 - precision_33: 1.0000 - recall_33: 1.0000 - auc_33: 1.0000 - val_loss: 1.1095 - val_acc: 0.6000 - val_precision_33: 1.0000 - val_recall_33: 0.4000 - val_auc_33: 0.7100\n",
      "Epoch 55/100\n",
      "35/35 [==============================] - 2s 59ms/step - loss: 0.0965 - acc: 1.0000 - precision_33: 1.0000 - recall_33: 1.0000 - auc_33: 1.0000 - val_loss: 1.1292 - val_acc: 0.6000 - val_precision_33: 1.0000 - val_recall_33: 0.4000 - val_auc_33: 0.6800\n",
      "Epoch 56/100\n",
      "35/35 [==============================] - 2s 49ms/step - loss: 0.0915 - acc: 1.0000 - precision_33: 1.0000 - recall_33: 1.0000 - auc_33: 1.0000 - val_loss: 1.1404 - val_acc: 0.6000 - val_precision_33: 1.0000 - val_recall_33: 0.4000 - val_auc_33: 0.7300\n",
      "Epoch 57/100\n",
      "35/35 [==============================] - 2s 51ms/step - loss: 0.0869 - acc: 1.0000 - precision_33: 1.0000 - recall_33: 1.0000 - auc_33: 1.0000 - val_loss: 1.1529 - val_acc: 0.6000 - val_precision_33: 1.0000 - val_recall_33: 0.4000 - val_auc_33: 0.7000\n",
      "Epoch 58/100\n",
      "35/35 [==============================] - 2s 50ms/step - loss: 0.0827 - acc: 1.0000 - precision_33: 1.0000 - recall_33: 1.0000 - auc_33: 1.0000 - val_loss: 1.1700 - val_acc: 0.6000 - val_precision_33: 1.0000 - val_recall_33: 0.4000 - val_auc_33: 0.7300\n",
      "Epoch 59/100\n",
      "35/35 [==============================] - 2s 59ms/step - loss: 0.0783 - acc: 1.0000 - precision_33: 1.0000 - recall_33: 1.0000 - auc_33: 1.0000 - val_loss: 1.1815 - val_acc: 0.6000 - val_precision_33: 1.0000 - val_recall_33: 0.4000 - val_auc_33: 0.7000\n",
      "Epoch 60/100\n",
      "35/35 [==============================] - 3s 76ms/step - loss: 0.0746 - acc: 1.0000 - precision_33: 1.0000 - recall_33: 1.0000 - auc_33: 1.0000 - val_loss: 1.1997 - val_acc: 0.6000 - val_precision_33: 1.0000 - val_recall_33: 0.4000 - val_auc_33: 0.6900\n",
      "Epoch 61/100\n",
      "35/35 [==============================] - 2s 70ms/step - loss: 0.0710 - acc: 1.0000 - precision_33: 1.0000 - recall_33: 1.0000 - auc_33: 1.0000 - val_loss: 1.2145 - val_acc: 0.6000 - val_precision_33: 1.0000 - val_recall_33: 0.4000 - val_auc_33: 0.7300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62/100\n",
      "12/35 [=========>....................] - ETA: 1s - loss: 0.0781 - acc: 1.0000 - precision_33: 1.0000 - recall_33: 1.0000 - auc_33: 1.0000"
     ]
    }
   ],
   "source": [
    "iterations = 1\n",
    "\n",
    "for i in range (iterations):\n",
    "   \n",
    "    l = preProcess(df_q_m)\n",
    "    all_words = []\n",
    "    for tweet in l:\n",
    "        tokenize_word = word_tokenize(tweet)\n",
    "        for word in tokenize_word:\n",
    "            all_words.append(word)\n",
    "    '''\n",
    "        Getting the unique words out\n",
    "    '''\n",
    "    unique_words = set(all_words)\n",
    "\n",
    "    '''\n",
    "        Getting embedded sentences\n",
    "    '''\n",
    "    vocab_length = len(unique_words)\n",
    "    embedded_sentences = [one_hot(tweet, vocab_length) for tweet in l]\n",
    "\n",
    "    '''\n",
    "        Making the size of all embeddings equal to the longest one\n",
    "    '''\n",
    "    word_count = lambda sentence: len(word_tokenize(sentence))\n",
    "    longest_sentence = max(l, key=word_count)\n",
    "    length_long_sentence = len(word_tokenize(longest_sentence))\n",
    "    padded_sentences = pad_sequences(embedded_sentences, length_long_sentence, padding='post')\n",
    "\n",
    "    '''\n",
    "        Model Paramters\n",
    "    '''\n",
    "    model = keras.Sequential()\n",
    "    model.add(Embedding(vocab_length, 100, input_length=padded_sentences.shape[1]))\n",
    "    model.add(LSTM(128, input_shape = (padded_sentences.shape[1], 1), dropout=0.2, return_sequences=True))\n",
    "    model.add(LSTM(64, return_sequences = True))\n",
    "    model.add(LSTM(32, return_sequences = True))\n",
    "    model.add(LSTM(16, return_sequences = True))\n",
    "    model.add(GlobalAveragePooling1D())\n",
    "    model.add(Dense(8, activation = 'relu', input_shape = (padded_sentences.shape[1],)))\n",
    "    #model.add(Dropout(0.5))\n",
    "    model.add(Dense(1, activation = 'sigmoid'))\n",
    "\n",
    "    '''\n",
    "        Compile and fit model\n",
    "    '''\n",
    "    model.compile(optimizer=keras.optimizers.RMSprop(lr = 0.0001),\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['acc', keras.metrics.Precision(), keras.metrics.Recall(), keras.metrics.AUC()])\n",
    "\n",
    "    history = model.fit(padded_sentences, t_q_m, batch_size=4, epochs=100, validation_split=0.3, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_30\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_30 (Embedding)     (None, 34, 100)           35700     \n",
      "_________________________________________________________________\n",
      "lstm_91 (LSTM)               (None, 34, 128)           117248    \n",
      "_________________________________________________________________\n",
      "lstm_92 (LSTM)               (None, 34, 64)            49408     \n",
      "_________________________________________________________________\n",
      "lstm_93 (LSTM)               (None, 34, 32)            12416     \n",
      "_________________________________________________________________\n",
      "lstm_94 (LSTM)               (None, 34, 16)            3136      \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_28  (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_54 (Dense)             (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "dense_55 (Dense)             (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 218,053\n",
      "Trainable params: 218,053\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x24bd7c6db38>"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "'''\n",
    "    Plotting accuracy VS epoch for training and validations\n",
    "'''\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs = range(1, len(acc) + 1)\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x24bd9d46128>"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "'''\n",
    "    Plotting loss VS epoch for training and validations\n",
    "'''\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 650,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Precision =  0.7223\n",
      "Stdev Precision =  0.23877699033012187\n",
      "Mean Recall =  0.79645\n",
      "Stdev Recall =  0.3232536095871338\n",
      "Mean ROC AUC =  0.82815\n",
      "Stdev ROC AUC =  0.04027536467867174\n"
     ]
    }
   ],
   "source": [
    "import statistics\n",
    "precision = [0.9231, 0.5625, 0.4545, 1, 0.5455, 0.5556, 0.75, 1, 1, 0.4318]\n",
    "recall = [1, 0.3, 0.4848, 1, 1, 1, 0.2273,1, 1, 0.9524]\n",
    "AUC = [0.7821, 0.8427, 0.8946, 0.8002, 0.8383, 0.8453,0.8874, 0.8, 0.8062, 0.7847 ]\n",
    "print('Mean Precision = ', statistics.mean(precision))\n",
    "print('Stdev Precision = ', statistics.stdev(precision))\n",
    "print('Mean Recall = ', statistics.mean(recall))\n",
    "print('Stdev Recall = ', statistics.stdev(recall))\n",
    "print('Mean ROC AUC = ', statistics.mean(AUC))\n",
    "print('Stdev ROC AUC = ', statistics.stdev(AUC))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.6609599],\n",
       "       [0.6609599],\n",
       "       [0.6609599],\n",
       "       [0.6609599],\n",
       "       [0.6609599],\n",
       "       [0.6609599],\n",
       "       [0.6609599],\n",
       "       [0.6609599],\n",
       "       [0.6609599],\n",
       "       [0.6609599],\n",
       "       [0.6609599],\n",
       "       [0.6609599],\n",
       "       [0.6609599],\n",
       "       [0.6609599],\n",
       "       [0.6609599]], dtype=float32)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict(history.validation_data[0])\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([201, 386,   3, 186, 159,  94, 201,  52,  24, 287, 268, 150,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_sentences[34]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(padded_sentences[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[361,  95, 201,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [290, 181, 201, 229,  74, 244, 354, 367, 201, 290, 181, 201, 229,\n",
       "          74, 244, 354,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [152, 266, 382, 278, 121, 164,  12,  22, 354, 197, 345, 288,  22,\n",
       "          95, 384, 180, 384, 257,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [119, 189,  93,  48, 146,  23,  87, 220, 284, 187, 303,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [272, 242, 141,  24,  17, 298, 158, 380, 378, 149,  71, 287, 310,\n",
       "         125, 103,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [ 77, 201, 303, 222, 287,  62, 148, 380,   6, 290, 229,  74, 380,\n",
       "         201, 117, 206, 287, 195,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [ 29, 342, 144,  63,  98, 183, 212, 144, 101,  31, 319, 358, 188,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [266,  21,  95, 165, 125,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [ 74,  40,  52, 202, 231, 183, 297, 103, 105,  95, 116, 175, 204,\n",
       "          52,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [ 86, 266, 342,  54, 118,  55, 271, 332,  95, 353, 148, 142,  19,\n",
       "         209, 230,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [ 64, 345, 125,  95,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [ 24, 142, 275, 142,  86,  95,  38,  95, 364, 275, 329, 320,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [ 46, 362, 205, 266, 287, 327,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [193,  74, 125, 191, 152, 302, 291, 369, 379, 206, 186,  71,  19,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [ 62, 263,  99,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0]]), array([[0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0]]), array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       dtype=float32), 0]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.validation_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_q_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Word Embeddings.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
