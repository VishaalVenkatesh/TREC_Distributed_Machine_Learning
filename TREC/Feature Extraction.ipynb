{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.probability import FreqDist\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from scipy.sparse import csr_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>ID</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Event</th>\n",
       "      <th>Retweet_Count</th>\n",
       "      <th>Follower_Count</th>\n",
       "      <th>Source</th>\n",
       "      <th>User_Created_at</th>\n",
       "      <th>Tweet_Created_at</th>\n",
       "      <th>User_Language</th>\n",
       "      <th>User_Screen_Name</th>\n",
       "      <th>User_Location</th>\n",
       "      <th>Event_Decrption</th>\n",
       "      <th>Categories</th>\n",
       "      <th>Priority</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1934</td>\n",
       "      <td>1934</td>\n",
       "      <td>451308164932440064</td>\n",
       "      <td>#ChileEarthquake Update: Chilean Interior Mini...</td>\n",
       "      <td>chileEarthquake2014</td>\n",
       "      <td>1</td>\n",
       "      <td>115158</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/#!/download/ipad\" ...</td>\n",
       "      <td>2008-11-14 14:14:03</td>\n",
       "      <td>2014-04-02 10:40:26</td>\n",
       "      <td>en</td>\n",
       "      <td>WLTX</td>\n",
       "      <td>Columbia, SC</td>\n",
       "      <td>The 2014 Iquique earthquake struck off the coa...</td>\n",
       "      <td>['ThirdPartyObservation', 'MultimediaShare', '...</td>\n",
       "      <td>Medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1935</td>\n",
       "      <td>1935</td>\n",
       "      <td>451293013763817472</td>\n",
       "      <td>Powerful earthquake strikes off the coast of C...</td>\n",
       "      <td>chileEarthquake2014</td>\n",
       "      <td>0</td>\n",
       "      <td>543</td>\n",
       "      <td>&lt;a href=\"http://twitterfeed.com\" rel=\"nofollow...</td>\n",
       "      <td>2014-01-21 12:26:37</td>\n",
       "      <td>2014-04-02 09:40:13</td>\n",
       "      <td>es</td>\n",
       "      <td>PiQkete_Online</td>\n",
       "      <td>à¸£Î±Ð¸Ñ‚Ïƒ DÏƒÐ¼iÐ¸gÏƒ Ñ”à¸£Ñ‚Ñ”</td>\n",
       "      <td>The 2014 Iquique earthquake struck off the coa...</td>\n",
       "      <td>['OriginalEvent']</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1936</td>\n",
       "      <td>1936</td>\n",
       "      <td>451285666350239744</td>\n",
       "      <td>#PrayForChile God is with you.</td>\n",
       "      <td>chileEarthquake2014</td>\n",
       "      <td>0</td>\n",
       "      <td>715</td>\n",
       "      <td>&lt;a href=\"http://twitter.com\" rel=\"nofollow\"&gt;Tw...</td>\n",
       "      <td>2011-08-16 01:50:33</td>\n",
       "      <td>2014-04-02 09:11:02</td>\n",
       "      <td>en</td>\n",
       "      <td>whatismylifex</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The 2014 Iquique earthquake struck off the coa...</td>\n",
       "      <td>['Sentiment']</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1937</td>\n",
       "      <td>1937</td>\n",
       "      <td>451300464269983744</td>\n",
       "      <td>Five dead after 8.2 magnitude earthquake off c...</td>\n",
       "      <td>chileEarthquake2014</td>\n",
       "      <td>1</td>\n",
       "      <td>3809</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/android\" ...</td>\n",
       "      <td>2011-02-11 22:02:54</td>\n",
       "      <td>2014-04-02 10:09:50</td>\n",
       "      <td>en</td>\n",
       "      <td>ShelleyBFox8</td>\n",
       "      <td>New Orleans</td>\n",
       "      <td>The 2014 Iquique earthquake struck off the coa...</td>\n",
       "      <td>['Factoid', 'News']</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1938</td>\n",
       "      <td>1938</td>\n",
       "      <td>451296996490346496</td>\n",
       "      <td>unbelievable img \"@Larryferlazzo RT @stevesilb...</td>\n",
       "      <td>chileEarthquake2014</td>\n",
       "      <td>0</td>\n",
       "      <td>157</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/android\" ...</td>\n",
       "      <td>2012-05-31 23:06:54</td>\n",
       "      <td>2014-04-02 09:56:03</td>\n",
       "      <td>en</td>\n",
       "      <td>WyattChrisJ</td>\n",
       "      <td>Australia</td>\n",
       "      <td>The 2014 Iquique earthquake struck off the coa...</td>\n",
       "      <td>['MultimediaShare', 'News']</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Unnamed: 0.1                  ID  \\\n",
       "0        1934          1934  451308164932440064   \n",
       "1        1935          1935  451293013763817472   \n",
       "2        1936          1936  451285666350239744   \n",
       "3        1937          1937  451300464269983744   \n",
       "4        1938          1938  451296996490346496   \n",
       "\n",
       "                                               Tweet                Event  \\\n",
       "0  #ChileEarthquake Update: Chilean Interior Mini...  chileEarthquake2014   \n",
       "1  Powerful earthquake strikes off the coast of C...  chileEarthquake2014   \n",
       "2                     #PrayForChile God is with you.  chileEarthquake2014   \n",
       "3  Five dead after 8.2 magnitude earthquake off c...  chileEarthquake2014   \n",
       "4  unbelievable img \"@Larryferlazzo RT @stevesilb...  chileEarthquake2014   \n",
       "\n",
       "   Retweet_Count  Follower_Count  \\\n",
       "0              1          115158   \n",
       "1              0             543   \n",
       "2              0             715   \n",
       "3              1            3809   \n",
       "4              0             157   \n",
       "\n",
       "                                              Source      User_Created_at  \\\n",
       "0  <a href=\"http://twitter.com/#!/download/ipad\" ...  2008-11-14 14:14:03   \n",
       "1  <a href=\"http://twitterfeed.com\" rel=\"nofollow...  2014-01-21 12:26:37   \n",
       "2  <a href=\"http://twitter.com\" rel=\"nofollow\">Tw...  2011-08-16 01:50:33   \n",
       "3  <a href=\"http://twitter.com/download/android\" ...  2011-02-11 22:02:54   \n",
       "4  <a href=\"http://twitter.com/download/android\" ...  2012-05-31 23:06:54   \n",
       "\n",
       "      Tweet_Created_at User_Language User_Screen_Name  \\\n",
       "0  2014-04-02 10:40:26            en             WLTX   \n",
       "1  2014-04-02 09:40:13            es   PiQkete_Online   \n",
       "2  2014-04-02 09:11:02            en    whatismylifex   \n",
       "3  2014-04-02 10:09:50            en     ShelleyBFox8   \n",
       "4  2014-04-02 09:56:03            en      WyattChrisJ   \n",
       "\n",
       "                       User_Location  \\\n",
       "0                       Columbia, SC   \n",
       "1  à¸£Î±Ð¸Ñ‚Ïƒ DÏƒÐ¼iÐ¸gÏƒ Ñ”à¸£Ñ‚Ñ”   \n",
       "2                                NaN   \n",
       "3                        New Orleans   \n",
       "4                          Australia   \n",
       "\n",
       "                                     Event_Decrption  \\\n",
       "0  The 2014 Iquique earthquake struck off the coa...   \n",
       "1  The 2014 Iquique earthquake struck off the coa...   \n",
       "2  The 2014 Iquique earthquake struck off the coa...   \n",
       "3  The 2014 Iquique earthquake struck off the coa...   \n",
       "4  The 2014 Iquique earthquake struck off the coa...   \n",
       "\n",
       "                                          Categories Priority  \n",
       "0  ['ThirdPartyObservation', 'MultimediaShare', '...   Medium  \n",
       "1                                  ['OriginalEvent']      Low  \n",
       "2                                      ['Sentiment']      Low  \n",
       "3                                ['Factoid', 'News']      Low  \n",
       "4                        ['MultimediaShare', 'News']      Low  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('Earthquake.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    Converting tweet column to str\n",
    "'''\n",
    "df['Tweet'] = df['Tweet'].astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    Generalise process to all files. Maybe later\n",
    "'''\n",
    "event_type = ['Floods', 'Earthquake', 'Bushfire', 'Bombings', 'Tornado', 'Attack', 'SchoolShooting', 'typhoon' ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Powerful',\n",
       " 'earthquake',\n",
       " 'strikes',\n",
       " 'off',\n",
       " 'the',\n",
       " 'coast',\n",
       " 'of',\n",
       " 'Chile',\n",
       " ':']"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "    Tokenize each tweet into words. Note we haven't yet removed stop words\n",
    "'''\n",
    "token_array = []\n",
    "for tweet in df['Tweet']:\n",
    "    token_tweet = word_tokenize(tweet)\n",
    "    token_array.append(token_tweet)\n",
    "                       \n",
    "token_array[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Powerful', 'earthquake', 'strikes', 'coast', 'Chile', ':']"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "    Will remove stop words from tweet. We still have to look into removing punctuation marks.\n",
    "'''\n",
    "stop_words=set(stopwords.words(\"english\"))\n",
    "filtered_token_array=[]\n",
    "for tweet in token_array:\n",
    "    filtered_tweet = []\n",
    "    for word in tweet:\n",
    "        if word not in stop_words:\n",
    "            filtered_tweet.append(word)\n",
    "    filtered_token_array.append(filtered_tweet)\n",
    "    \n",
    "filtered_token_array[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['power', 'earthquak', 'strike', 'coast', 'chile', ':']"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "    We will now do stemming. This is the process of removing different forms of the same word and will\n",
    "    resort to the root word. For example, connection, connected, connecting word reduce to a common \n",
    "    word \"connect\".\n",
    "'''\n",
    "ps = PorterStemmer()\n",
    "stemmed_array=[]\n",
    "for tweet in filtered_token_array:\n",
    "    stemmed_tweet = []\n",
    "    for word in tweet:\n",
    "        stemmed_tweet.append(ps.stem(word))\n",
    "    stemmed_array.append(stemmed_tweet)\n",
    "    \n",
    "stemmed_array[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Powerful', 'earthquake', 'strike', 'coast', 'Chile', ':']"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "    We now do lemmatization. This is like stemming but more effective apparently as it does a dictionary lookup. For \n",
    "    instance a relation between the words good and better may be made in lemmatisation but not in stemming.\n",
    "    \n",
    "    Lemmatization is much better from a cursory look. Words like earthquake are being cut down to earthquak \n",
    "    when using stemming. \n",
    "'''\n",
    "lem = WordNetLemmatizer()\n",
    "stem = PorterStemmer()\n",
    "\n",
    "lemmatized_array=[]\n",
    "for tweet in filtered_token_array:\n",
    "    lemmatized_tweet = []\n",
    "    for word in tweet:\n",
    "        lemmatized_tweet.append(lem.lemmatize(word,'v'))\n",
    "    lemmatized_array.append(lemmatized_tweet)\n",
    "    \n",
    "lemmatized_array[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    DTM to get bag of words\n",
    "'''\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv = CountVectorizer(lowercase=True,stop_words='english',ngram_range = (1,1),tokenizer = token.tokenize)\n",
    "text_counts= cv.fit_transform(df['Tweet'])\n",
    "text_counts_dense = text_counts.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    DTM to get TF-IDF features\n",
    "'''\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tf=TfidfVectorizer()\n",
    "text_tf= tf.fit_transform(df['Tweet'])\n",
    "text_tf_dense = text_tf.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8252, 15025)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_counts_dense.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8252, 15437)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_tf_dense.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_counts_dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "82053"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.count_nonzero(text_counts_dense)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "123986300"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "8252*15025"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
